{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a data set and build a KNN Regression and an OLS regression. Compare the two. How similar are they? Do they miss in different ways?\n",
    "\n",
    "Create a Jupyter notebook with your models. At the end in a markdown cell write a few paragraphs to describe the models' behaviors and why you favor one model or the other. Try to determine whether there is a situation where you would change your mind, or whether one is unambiguously better than the other. Lastly, try to note what it is about the data that causes the better model to outperform the weaker model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "# Suppress annoying harmless error.\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Normalizing the Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Access the data file from the FBI: UCR \n",
    "dataset = pd.read_excel(\"NYCCrime.xls\", header=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the dataset into a DataFrame\n",
    "data = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Access the Columns desired for this challenge\n",
    "data_group = data.loc[:, ['Population', 'Property\\ncrime', 'Robbery', 'Burglary', 'Larceny-\\ntheft']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename the group columns\n",
    "data_group.columns = ['Population', 'Property_crime', 'Robbery', 'Burglary', 'Theft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop the remaining null values in every column. \n",
    "data_group = data_group.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to remove outlier data\n",
    "def reject_outliers(data, m=2):\n",
    "    return data[abs(data - np.mean(data)) < m * np.std(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter the continuous variables through the outlier removal function and then drop the null values. \n",
    "for group in data_group.loc[:, 'Population':]:\n",
    "    data_group[group] = reject_outliers(data_group[group], m=2)\n",
    "data_group = data_group.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Normalize each of the features in the dataframe\n",
    "scaled_features = StandardScaler().fit_transform(data_group.values)\n",
    "# Create a new dataframe with these rescaled values but maintain the previous indexes and column names. \n",
    "scaled_features_df = pd.DataFrame(scaled_features, index=data_group.index, columns=data_group.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Linear and KNN models with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression model\n",
    "\n",
    "In a linear regression model it operates by finding estimators for coefficients in a formula that is defined to explain the relationship between variables. In this example the theft, burglary, robbery, and population features are used as independent variables to predict the dependent variable, property crime. A linear regression assumes that the relationship between the predictors and the outcome is linear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My linear regression model. \n",
    "regr = linear_model.LinearRegression()\n",
    "# Dependent variable\n",
    "Y = scaled_features_df['Property_crime'].values.reshape(-1, 1)\n",
    "# Independent variables\n",
    "X = scaled_features_df[['Theft', 'Burglary', 'Robbery', 'Population']]\n",
    "# Fitting my variables to the linear model\n",
    "regr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coefficients: \n",
      " [[ 0.74749402  0.24519983  0.02789408  0.00676561]]\n",
      "\n",
      "Intercept: \n",
      " [ -5.28605865e-17]\n",
      "\n",
      "Each Cross Validated R2 score: \n",
      " [ 0.9999052   0.99976608  0.99953834  0.99954907  0.9995398 ]\n",
      "\n",
      "Overall Linear Regression R2: 1.00 (+/- 0.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nCoefficients: \\n', regr.coef_)\n",
    "print('\\nIntercept: \\n', regr.intercept_)\n",
    "score = cross_val_score(regr, X, Y, cv=5)\n",
    "print('\\nEach Cross Validated R2 score: \\n', score)\n",
    "print(\"\\nOverall Linear Regression R2: %0.2f (+/- %0.2f)\\n\" % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors model\n",
    "\n",
    "In a K-nearest neighbor model it learns through similarity. It looks for the data points that are most similar to the observation being predicted. To predict an observation, it finds the closest (or nearest) known observation in our training data and use that value to make our prediction. In this model a 4D space is created with the independent variables and then its corresponding property crime or dependent value. The K-nearest neighbor model looks at multiple neighboring values and each of these data points \"vote\" for a predicted property crime value. These votes then become a weighted average and returned as the predicted value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
       "          weights='distance')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My K-nearest neighbor regressor model\n",
    "knn = neighbors.KNeighborsRegressor(n_neighbors=2, weights='distance')\n",
    "# Dependent variable\n",
    "Y = scaled_features_df['Property_crime'].values.reshape(-1, 1)\n",
    "# Independent variables\n",
    "X = scaled_features_df[['Theft', 'Burglary', 'Robbery', 'Population']]\n",
    "# Fitting my variables to the KNN model\n",
    "knn.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Each Cross Validated R2 score: \n",
      " [ 0.94834599  0.98342286  0.97749222  0.97621985  0.84722475]\n",
      "\n",
      "Overall KNN Regression R2: 0.95 (+/- 0.10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_score = cross_val_score(knn, X, Y, cv=5)\n",
    "print('\\nEach Cross Validated R2 score: \\n', knn_score)\n",
    "print(\"\\nOverall KNN Regression R2: %0.2f (+/- %0.2f)\\n\" % (knn_score.mean(), knn_score.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this scenario I favor my linear regression model because of its more consistent and better performance. My linear regression model's R-squared values were higher through each cross validation grouping compared to the K-nearest neighbor regressor model. I believe that the linear regression model outperformed the KNN model because the data for the predictors and the property crime have a very clear linear relationship. However, my KNN model still performed remarkably well and if I was working with a dataset that had a non-linear or more complicated relationships then it would likely be a better choice than a linear regression model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
