{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import re\n",
    "import csv\n",
    "from scipy import stats, integrate\n",
    "from scipy.stats import spearmanr\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here is the \"dirty\" data file that I need to clean\n",
    "dirty = pd.read_csv('DataCleaning.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I made a blank data frame that was as long as the dirty data set and then transferred over the columns that were\n",
    "# applicable to my assignment. \n",
    "data = pd.DataFrame(index=range(len(dirty)))\n",
    "data['Publisher'] = dirty['Publisher']\n",
    "data['Journal'] = dirty['Journal title']\n",
    "data['Articles']= dirty['Article title']\n",
    "data['cost_per_article'] = dirty['COST (£) charged to Wellcome (inc VAT when charged)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I dropped the null values in my data set so that I could run functions through it. \n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am making a dictionary with the acronyms of each journal and it's corresponding full name. \n",
    "def journal_acronym(series):\n",
    "    # This is the empty dictionary\n",
    "    dictionary = {}\n",
    "    # Iterating through each row in the series.\n",
    "    for item in series:\n",
    "        # If the row is less than 3 words long then I skip this step\n",
    "        if len(item.split()) > 2:\n",
    "            # Split each row into words\n",
    "            separate = item.split()\n",
    "            # This is an empty key\n",
    "            key = ''\n",
    "            for word in separate:\n",
    "                # Skip over these words\n",
    "                if word.lower() != 'of' and word.lower() != 'and' and word.lower() != 'the' and word.lower() != '&':\n",
    "                    # Now take the first letter of each word, capitalize it and concate it to the 'key'. \n",
    "                    key = key+word[0].upper()\n",
    "            # Now make that the 'key' of the item that you iterated through and enter it into the dictionary. \n",
    "            dictionary[key] = item\n",
    "    # return the dictionary with the key:value items from the series       \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "journal_dict = journal_acronym(data['Journal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def journal_replace(series):\n",
    "    # Iterating through each row in the series.\n",
    "    for item in series:\n",
    "        # If the row is less than 3 words long then I skip this step\n",
    "        if len(item.split()) > 2:\n",
    "            # Split each row into words\n",
    "            separate = item.split()\n",
    "            key = ''\n",
    "            for word in separate:\n",
    "                # Skip over these words\n",
    "                if word.lower() != 'of' and word.lower() != 'and' and word.lower() != 'the' and word.lower() != '&':\n",
    "                    # Now take the first letter of each word, capitalize it and concate it to the 'key'. \n",
    "                    key = key+word[0].upper()\n",
    "            # If that key is in the previously made journal dictionary\n",
    "            if key in journal_dict:\n",
    "                # Then replace the current item that is being iterated through with the value from that dictionary\n",
    "                series.replace(item, journal_dict[key], inplace = True)\n",
    "    # return the modified series\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now I'm replacing the current data['Journal'] column with the modified journals from the journal_replace function\n",
    "data['Journal'] = journal_replace(data['Journal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before I answer this challenge questions, I'm going to strip the data['cost_per_article'] column of £ and $ and \n",
    "# change it into a float variable. \n",
    "data['cost_per_article'].update(data['cost_per_article'].apply(lambda x: float(str(x).strip('£ | $'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the five most common journals and the total articles for each. Next, calculate the mean, median, and standard deviation of the open-access cost per article for each journal . You will need to do considerable data cleaning in order to extract accurate estimates. For a real bonus round, identify the open access prices paid by subject area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Journal\n",
       "PLoS One                     92\n",
       "Jnl Biological Chemistry     71\n",
       "PLoS ONE                     62\n",
       "JOURNAL OF NEUROCHEMISTRY    34\n",
       "Nucleic Acids Research\\n     29\n",
       "Name: Articles, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here I've grouped by the data['Journal'] column and have it only counting the number of 'Articles' and then I sort\n",
    "# my values by descending order and limit it to the top five values. \n",
    "data.groupby(data['Journal'])['Articles'].count().sort_values(ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24732.8433696\n",
      "894.22\n",
      "147540.721101\n"
     ]
    }
   ],
   "source": [
    "# Now I isolated all the columns where the Journal was for PLoS One and then printed out the mean, median, and \n",
    "# standard deviation of its cost_per_article. \n",
    "PLoSOne = data.loc[data.Journal=='PLoS One', :]\n",
    "print(PLoSOne['cost_per_article'].mean())\n",
    "print(PLoSOne['cost_per_article'].median())\n",
    "print(PLoSOne['cost_per_article'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29515.7440845\n",
      "1324.57\n",
      "166402.487895\n"
     ]
    }
   ],
   "source": [
    "# Now I isolated all the columns where the Journal was for Jnl Biological Chemistry and then printed out the mean, \n",
    "# median, and standard deviation of its cost_per_article.\n",
    "JnlBiologicalChemistry = data.loc[data.Journal=='Jnl Biological Chemistry', :]\n",
    "print(JnlBiologicalChemistry['cost_per_article'].mean())\n",
    "print(JnlBiologicalChemistry['cost_per_article'].median())\n",
    "print(JnlBiologicalChemistry['cost_per_article'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49248.7172581\n",
      "890.095\n",
      "216138.48622\n"
     ]
    }
   ],
   "source": [
    "# Now I isolated all the columns where the Journal was for PLoS ONE and then printed out the mean, median, and \n",
    "# standard deviation of its cost_per_article. \n",
    "PLoSONE = data.loc[data.Journal=='PLoS ONE', :]\n",
    "print(PLoSONE['cost_per_article'].mean())\n",
    "print(PLoSONE['cost_per_article'].median())\n",
    "print(PLoSONE['cost_per_article'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31202.0941176\n",
      "1909.19\n",
      "171182.810111\n"
     ]
    }
   ],
   "source": [
    "# Now I isolated all the columns where the Journal was for JOURNAL OF NEUROCHEMISTRY and then printed out the mean, \n",
    "# median, and standard deviation of its cost_per_article. \n",
    "JOURNALofNEUROCHEMISTRY = data.loc[data.Journal=='JOURNAL OF NEUROCHEMISTRY', :]\n",
    "print(JOURNALofNEUROCHEMISTRY['cost_per_article'].mean())\n",
    "print(JOURNALofNEUROCHEMISTRY['cost_per_article'].median())\n",
    "print(JOURNALofNEUROCHEMISTRY['cost_per_article'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1162.34482759\n",
      "852.0\n",
      "442.150933818\n"
     ]
    }
   ],
   "source": [
    "# Now I isolated all the columns where the Journal was for Nucleic Acids Research\\n and then printed out the mean, \n",
    "# median, and standard deviation of its cost_per_article. \n",
    "NucleicAcidsResearch = data.loc[data.Journal=='Nucleic Acids Research\\n', :]\n",
    "print(NucleicAcidsResearch['cost_per_article'].mean())\n",
    "print(NucleicAcidsResearch['cost_per_article'].median())\n",
    "print(NucleicAcidsResearch['cost_per_article'].std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
